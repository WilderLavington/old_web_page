# Tutorials
This page contains links to a couple of the code along tutorials I have created over the last couple years, either for courses, teaching assistantships, or just for fun! If something looks interesting, just click on thhe title to be re-directed to the page containing the notebook. Everything is ordered by subject, and the year that I created it, bon appetite.

[Maximum entropy policy gradients:](https://github.com/WilderLavington/WilderLavington.github.io/blob/master/tutorial/Maximum_Entropy_Policy_Gradients.ipynb)   
 This tutorial reviews a simple implimentation of maximum entropy policy gradients applied to a simple, fully observed markov descion proccess. This is the first in a series of tutorials that leads up to eventually implimenting a solution of to a high dimentional reinforcement in a probabalistic programming language, and reviews all the advantages and pitfall of this methodology.

[Generalized Advantage Estimation:](https://github.com/WilderLavington/WilderLavington.github.io/blob/master/tutorial/Generalized_Advantage_Estimation.ipynb) 
This tutorial sets up the generalized advantage estimator described in https://arxiv.org/abs/1506.02438, within a simple discrete, fully observed MDP setting. 
