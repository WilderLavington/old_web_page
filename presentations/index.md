# Presentations 

Below I have included a few of the projects that I have completed over the past couple years. They mostly pertain to topics in machine learning, artificial intelligence, numerical analysis, and statistical inference. To view the slides for the project, just click on the link!

## 2018 
[Imitation Learning Tutorial and Overview](https://wilderlavington.github.io/presentations/presentations/Imitation_Learning.pdf)  
This presentation was created for the machine learning reading group at UBC and was based upon various papers surrounding 
maximum entropy reainforcement learning, inverse reinforcement learning, apprentishp learning, and of course imitation learning. The presentation was mainly focused on making explicit connections between these seemingly disjoint topics in a rigourous but interpretable fashion.

[Pi calculus Tutorial and Overview](https://wilderlavington.github.io/presentations/presentations/Programming_Language_Principles_Presentation.pdf)   
This was presented in a programming language principles course tought by Ron Garcia that focused on a specific forn of proccess calculus known as pi calculus. This calcus is used to model how information is passed from servers to clients in from a rigorous PL perspective, and is relevent in software engineering and network security.

[Variational Autoencoders Tutorial and Overview](https://wilderlavington.github.io/presentations/presentations/VAE_presentation.pdf)   
This presentation was created for a probabalitsic programming course taught by Frank Wood, and focuses on three seminal papers that form the genesis of modern variational autoencoders. Aside from giving a breif summary of these papers, we also attempt to inform how each relates to another. Additionally, we give a breif overview of current topics in VAEs.

## 2017
[Leveraging Graph Diversity Under Constraints](https://wilderlavington.github.io/presentations/presentations/Leveraging_Graphical_Diversity_Under_Constraints_to_Predict_Structure.pdf)
This presentation was created for a network analysis and modeling course taught by Aaron Clausett, and focused on how restricting specific structural elements within networks, we can infer other structural constraints. Addionally, we showed that the joint joint degree distribution could act as a unique similarty metric under such constraints, allowing us to accuratly predict the random graph structure that a given graph was sampled from. 
